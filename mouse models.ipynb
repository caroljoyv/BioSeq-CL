{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cacd3b6e",
   "metadata": {},
   "source": [
    "# Importing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d147456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53062c",
   "metadata": {},
   "source": [
    "# Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58bbf567",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding = pd.read_csv(\"mouse_coding_9_features.csv\")\n",
    "noncoding = pd.read_csv(\"mouse_noncoding_9_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8397bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66799, 12)\n"
     ]
    }
   ],
   "source": [
    "#replace ORF ratio\n",
    "coding[\"ORF Ratio\"] = coding[\"ORF Length\"] / coding[\"Transcript Length\"]\n",
    "\n",
    "#add new feature\n",
    "coding[\"CpG Islands per ORF Length\"] = coding[\"CpG Islands\"] / coding[\"ORF Length\"]\n",
    "\n",
    "#add new feature\n",
    "coding[\"GC content per ORF Length\"] = coding[\"GC content\"] / coding[\"ORF Length\"]\n",
    "\n",
    "#adding labels\n",
    "coding[\"coding/noncoding\"] = 1\n",
    "\n",
    "print(coding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36f727d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26400, 12)\n"
     ]
    }
   ],
   "source": [
    "#replace ORF ratio\n",
    "noncoding[\"ORF Ratio\"] = noncoding[\"ORF Length\"] / noncoding[\"Transcript Length\"]\n",
    "\n",
    "#add new feature\n",
    "noncoding[\"CpG Islands per ORF Length\"] = noncoding[\"CpG Islands\"] / noncoding[\"ORF Length\"]\n",
    "\n",
    "#add new feature\n",
    "noncoding[\"GC content per ORF Length\"] = noncoding[\"GC content\"] / noncoding[\"ORF Length\"]\n",
    "\n",
    "#adding labels\n",
    "noncoding[\"coding/noncoding\"] = 0\n",
    "\n",
    "print(noncoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a016d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking 26400 sequences from both dataframes\n",
    "noncoding = noncoding.head(26400)\n",
    "coding = coding.head(26400)\n",
    "\n",
    "# combining both dataframes\n",
    "dataset = coding.merge(noncoding, how = \"outer\")\n",
    "\n",
    "# shuffle the dataset\n",
    "shuffled_dataset = dataset.sample(frac=1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5de44725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fickett Score                  0\n",
      "GC content                     0\n",
      "CpG Islands                    0\n",
      "Transcript Length              0\n",
      "ORF Length                     0\n",
      "ORF Ratio                      0\n",
      "Relative Codon Bias            0\n",
      "Isoelectric Potential          0\n",
      "Aromaticity                    0\n",
      "coding/noncoding               0\n",
      "CpG Islands per ORF Length    23\n",
      "GC content per ORF Length      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dab7cb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fickett Score                   0\n",
      "GC content                      0\n",
      "CpG Islands                     0\n",
      "Transcript Length               0\n",
      "ORF Length                      0\n",
      "ORF Ratio                       0\n",
      "Relative Codon Bias             0\n",
      "Isoelectric Potential           0\n",
      "Aromaticity                     0\n",
      "coding/noncoding                0\n",
      "CpG Islands per ORF Length    493\n",
      "GC content per ORF Length     516\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.isinf(shuffled_dataset).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12bc4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c347d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fba896f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fickett Score                 0\n",
      "GC content                    0\n",
      "CpG Islands                   0\n",
      "Transcript Length             0\n",
      "ORF Length                    0\n",
      "ORF Ratio                     0\n",
      "Relative Codon Bias           0\n",
      "Isoelectric Potential         0\n",
      "Aromaticity                   0\n",
      "coding/noncoding              0\n",
      "CpG Islands per ORF Length    0\n",
      "GC content per ORF Length     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec394c3",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312af508",
   "metadata": {},
   "source": [
    "## F5 - ORF len + FS + ORF Ratio + GCC + trans len + RCB + AR + IP + CpG/ORF +GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b96e5efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8803977272727272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop(\"coding/noncoding\", axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create the logistic regression classifier and fit it to the training data\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f51d2650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9228003384094755\n",
      "Recall:  0.8293100171070139\n",
      "F1 Score:  0.8735609170087096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c1c465",
   "metadata": {},
   "source": [
    "## F4 - ORF len + FS + AR + IP + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "092c3173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8806818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"ORF Ratio\",\"GC content\"], axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create the logistic regression classifier and fit it to the training data\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "333f51f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9239245602881967\n",
      "Recall:  0.8287397833111576\n",
      "F1 Score:  0.87374749498998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564405df",
   "metadata": {},
   "source": [
    "## F3 - ORF len + FS + ORF Ratio + AR + IP + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2089521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8794507575757575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"GC content\"], axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the logistic regression classifier and fit it to the training data\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "833c5924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9229953330504879\n",
      "Recall:  0.8270290819235887\n",
      "F1 Score:  0.8723809523809523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c2d3d2",
   "metadata": {},
   "source": [
    "## F2 - ORF len + FS + ORF Ratio + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6ac568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8783143939393939\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"GC content\",\"Aromaticity\",\"Relative Codon Bias\",\"Isoelectric Potential\"], axis=1)  # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the logistic regression classifier and fit it to the training data\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc558a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9204737732656514\n",
      "Recall:  0.8272191598555407\n",
      "F1 Score:  0.8713584943437781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72c9114",
   "metadata": {},
   "source": [
    "## F1 - ORF len + FS + ORF Ratio + CpG/ORF + GC/ORF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a236e842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8782196969696969\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"CpG Islands\",\"Transcript Length\",\"GC content\",\"Aromaticity\",\"Relative Codon Bias\",\"Isoelectric Potential\"], axis=1)   # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the logistic regression classifier and fit it to the training data\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bce3f39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9193922768516565\n",
      "Recall:  0.8281695495153013\n",
      "F1 Score:  0.8714000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f3f635",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3593ed9a",
   "metadata": {},
   "source": [
    "## F1 - ORF len + FS + ORF Ratio + CpG/ORF + GC/ORF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2eab6163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8929924242424242\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"CpG Islands\",\"Transcript Length\",\"GC content\",\"Aromaticity\",\"Relative Codon Bias\",\"Isoelectric Potential\"], axis=1)   # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14087709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9115361625821877\n",
      "Recall:  0.8696065386808591\n",
      "F1 Score:  0.8900778210116732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538fba33",
   "metadata": {},
   "source": [
    "## F2 - ORF len + FS + ORF Ratio + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "723646b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89375\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"GC content\",\"Aromaticity\",\"Relative Codon Bias\",\"Isoelectric Potential\"], axis=1)  # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53d8d91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9172\n",
      "Recall:  0.8716973959323323\n",
      "F1 Score:  0.8938699931780529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e551c",
   "metadata": {},
   "source": [
    "## F3 - ORF len + FS + ORF Ratio + AR + IP + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4c65cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.896875\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"GC content\"], axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18c8b3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9172\n",
      "Recall:  0.8716973959323323\n",
      "F1 Score:  0.8938699931780529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf69cebf",
   "metadata": {},
   "source": [
    "## F4 - ORF len + FS + AR + IP + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab02cd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.893560606060606\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"ORF Ratio\",\"GC content\"], axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b91df5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9144460028050491\n",
      "Recall:  0.8675156814293861\n",
      "F1 Score:  0.8903628560280921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afd8350",
   "metadata": {},
   "source": [
    "## F5 - ORF len + FS + ORF Ratio + GCC + trans len + RCB + AR + IP + CpG/ORF +GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "208061c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9025568181818182\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop(\"coding/noncoding\", axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac646545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9243882872041717\n",
      "Recall:  0.8760691883672306\n",
      "F1 Score:  0.8995803649848736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ba8589",
   "metadata": {},
   "source": [
    "# Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ba5e7",
   "metadata": {},
   "source": [
    "## F5 - ORF len + FS + ORF Ratio + GCC + trans len + RCB + AR + IP + CpG/ORF +GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb76db7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8262310606060606\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop(\"coding/noncoding\", axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "541bafb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.92825\n",
      "Recall:  0.7057593613381486\n",
      "F1 Score:  0.8018572508368428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a49188",
   "metadata": {},
   "source": [
    "## F4 - ORF len + FS + AR + IP + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d3fd616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8290719696969697\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"ORF Ratio\",\"GC content\"], axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "63156768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9266666666666666\n",
      "Recall:  0.7133624786162327\n",
      "F1 Score:  0.80614327139942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9170a3b3",
   "metadata": {},
   "source": [
    "## F3 - ORF len + FS + ORF Ratio + AR + IP + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ead8ab4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8357954545454546\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"GC content\",\"Aromaticity\",\"Relative Codon Bias\",\"Isoelectric Potential\"], axis=1)  # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "143ddd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9319128092089151\n",
      "Recall:  0.7232465310777418\n",
      "F1 Score:  0.8144263698630136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a11662",
   "metadata": {},
   "source": [
    "## F2 - ORF len + FS + ORF Ratio + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d68bba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bacb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
