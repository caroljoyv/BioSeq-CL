{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e138ba6",
   "metadata": {},
   "source": [
    "# Importing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "044e3a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e02fd",
   "metadata": {},
   "source": [
    "# Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c485c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding = pd.read_csv(\"mouse_coding_9_features.csv\")\n",
    "noncoding = pd.read_csv(\"mouse_noncoding_9_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68064a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66799, 12)\n"
     ]
    }
   ],
   "source": [
    "#replace ORF ratio\n",
    "coding[\"ORF Ratio\"] = coding[\"ORF Length\"] / coding[\"Transcript Length\"]\n",
    "\n",
    "#add new feature\n",
    "coding[\"CpG Islands per ORF Length\"] = coding[\"CpG Islands\"] / coding[\"ORF Length\"]\n",
    "\n",
    "#add new feature\n",
    "coding[\"GC content per ORF Length\"] = coding[\"GC content\"] / coding[\"ORF Length\"]\n",
    "\n",
    "#adding labels\n",
    "coding[\"coding/noncoding\"] = 1\n",
    "\n",
    "print(coding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb736214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26400, 12)\n"
     ]
    }
   ],
   "source": [
    "#replace ORF ratio\n",
    "noncoding[\"ORF Ratio\"] = noncoding[\"ORF Length\"] / noncoding[\"Transcript Length\"]\n",
    "\n",
    "#add new feature\n",
    "noncoding[\"CpG Islands per ORF Length\"] = noncoding[\"CpG Islands\"] / noncoding[\"ORF Length\"]\n",
    "\n",
    "#add new feature\n",
    "noncoding[\"GC content per ORF Length\"] = noncoding[\"GC content\"] / noncoding[\"ORF Length\"]\n",
    "\n",
    "#adding labels\n",
    "noncoding[\"coding/noncoding\"] = 0\n",
    "\n",
    "print(noncoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef21e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking 26400 sequences from both dataframes\n",
    "noncoding = noncoding.head(26400)\n",
    "coding = coding.head(26400)\n",
    "\n",
    "# combining both dataframes\n",
    "dataset = coding.merge(noncoding, how = \"outer\")\n",
    "\n",
    "# shuffle the dataset\n",
    "shuffled_dataset = dataset.sample(frac=1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f042eac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fickett Score                  0\n",
      "GC content                     0\n",
      "CpG Islands                    0\n",
      "Transcript Length              0\n",
      "ORF Length                     0\n",
      "ORF Ratio                      0\n",
      "Relative Codon Bias            0\n",
      "Isoelectric Potential          0\n",
      "Aromaticity                    0\n",
      "coding/noncoding               0\n",
      "CpG Islands per ORF Length    23\n",
      "GC content per ORF Length      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a562b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fickett Score                   0\n",
      "GC content                      0\n",
      "CpG Islands                     0\n",
      "Transcript Length               0\n",
      "ORF Length                      0\n",
      "ORF Ratio                       0\n",
      "Relative Codon Bias             0\n",
      "Isoelectric Potential           0\n",
      "Aromaticity                     0\n",
      "coding/noncoding                0\n",
      "CpG Islands per ORF Length    493\n",
      "GC content per ORF Length     516\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.isinf(shuffled_dataset).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcee8bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e81c9725",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e95ec250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fickett Score                 0\n",
      "GC content                    0\n",
      "CpG Islands                   0\n",
      "Transcript Length             0\n",
      "ORF Length                    0\n",
      "ORF Ratio                     0\n",
      "Relative Codon Bias           0\n",
      "Isoelectric Potential         0\n",
      "Aromaticity                   0\n",
      "coding/noncoding              0\n",
      "CpG Islands per ORF Length    0\n",
      "GC content per ORF Length     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7c57a",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653f49a9",
   "metadata": {},
   "source": [
    "## F5 - ORF len + FS + ORF Ratio + GCC + trans len + RCB + AR + IP + CpG/ORF +GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37905293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8803977272727272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop(\"coding/noncoding\", axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create the logistic regression classifier and fit it to the training data\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3aad608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9228003384094755\n",
      "Recall:  0.8293100171070139\n",
      "F1 Score:  0.8735609170087096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e508c0a",
   "metadata": {},
   "source": [
    "## F4 - ORF len + FS + AR + IP + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "049c13cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8806818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"ORF Ratio\",\"GC content\"], axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create the logistic regression classifier and fit it to the training data\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ffe2833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9239245602881967\n",
      "Recall:  0.8287397833111576\n",
      "F1 Score:  0.87374749498998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6dd032",
   "metadata": {},
   "source": [
    "## F3 - ORF len + FS + ORF Ratio + AR + IP + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48004a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8794507575757575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"GC content\"], axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the logistic regression classifier and fit it to the training data\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "889ad785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9229953330504879\n",
      "Recall:  0.8270290819235887\n",
      "F1 Score:  0.8723809523809523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d1ed3",
   "metadata": {},
   "source": [
    "## F2 - ORF len + FS + ORF Ratio + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fbfa358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8783143939393939\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"GC content\",\"Aromaticity\",\"Relative Codon Bias\",\"Isoelectric Potential\"], axis=1)  # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the logistic regression classifier and fit it to the training data\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "238395de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9204737732656514\n",
      "Recall:  0.8272191598555407\n",
      "F1 Score:  0.8713584943437781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b08963",
   "metadata": {},
   "source": [
    "## F1 - ORF len + FS + ORF Ratio + CpG/ORF + GC/ORF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e67a0255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8782196969696969\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"CpG Islands\",\"Transcript Length\",\"GC content\",\"Aromaticity\",\"Relative Codon Bias\",\"Isoelectric Potential\"], axis=1)   # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the logistic regression classifier and fit it to the training data\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a77e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9193922768516565\n",
      "Recall:  0.8281695495153013\n",
      "F1 Score:  0.8714000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df76c0f5",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d0ed90",
   "metadata": {},
   "source": [
    "## F1 - ORF len + FS + ORF Ratio + CpG/ORF + GC/ORF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f04f37e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8929924242424242\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"CpG Islands\",\"Transcript Length\",\"GC content\",\"Aromaticity\",\"Relative Codon Bias\",\"Isoelectric Potential\"], axis=1)   # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8a040f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9115361625821877\n",
      "Recall:  0.8696065386808591\n",
      "F1 Score:  0.8900778210116732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558ccaf",
   "metadata": {},
   "source": [
    "## F2 - ORF len + FS + ORF Ratio + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1e3094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89375\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"GC content\",\"Aromaticity\",\"Relative Codon Bias\",\"Isoelectric Potential\"], axis=1)  # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0734225e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9172\n",
      "Recall:  0.8716973959323323\n",
      "F1 Score:  0.8938699931780529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0776be",
   "metadata": {},
   "source": [
    "## F3 - ORF len + FS + ORF Ratio + AR + IP + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "439f290e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.896875\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"GC content\"], axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c01030d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9172\n",
      "Recall:  0.8716973959323323\n",
      "F1 Score:  0.8938699931780529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed5f13",
   "metadata": {},
   "source": [
    "## F4 - ORF len + FS + AR + IP + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70b11a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.893560606060606\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"ORF Ratio\",\"GC content\"], axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a53a50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9144460028050491\n",
      "Recall:  0.8675156814293861\n",
      "F1 Score:  0.8903628560280921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e03604",
   "metadata": {},
   "source": [
    "## F5 - ORF len + FS + ORF Ratio + GCC + trans len + RCB + AR + IP + CpG/ORF +GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "591b8945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9025568181818182\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop(\"coding/noncoding\", axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4cf9a826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9243882872041717\n",
      "Recall:  0.8760691883672306\n",
      "F1 Score:  0.8995803649848736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8d414",
   "metadata": {},
   "source": [
    "# Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b0e77",
   "metadata": {},
   "source": [
    "## F5 - ORF len + FS + ORF Ratio + GCC + trans len + RCB + AR + IP + CpG/ORF +GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af168ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8262310606060606\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop(\"coding/noncoding\", axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "906b2360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.92825\n",
      "Recall:  0.7057593613381486\n",
      "F1 Score:  0.8018572508368428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1668789",
   "metadata": {},
   "source": [
    "## F4 - ORF len + FS + AR + IP + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b9e0a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8290719696969697\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"ORF Ratio\",\"GC content\"], axis=1) # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ba03875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9266666666666666\n",
      "Recall:  0.7133624786162327\n",
      "F1 Score:  0.80614327139942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212484a1",
   "metadata": {},
   "source": [
    "## F3 - ORF len + FS + ORF Ratio + AR + IP + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f61bf384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8357954545454546\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"GC content\",\"Aromaticity\",\"Relative Codon Bias\",\"Isoelectric Potential\"], axis=1)  # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ae18854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9319128092089151\n",
      "Recall:  0.7232465310777418\n",
      "F1 Score:  0.8144263698630136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61769aac",
   "metadata": {},
   "source": [
    "## F2 - ORF len + FS + ORF Ratio + CpG/ORF + GC/ORF + CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1af557d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8357954545454546\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"Transcript Length\",\"GC content\",\"Aromaticity\",\"Relative Codon Bias\",\"Isoelectric Potential\"], axis=1)  # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3ccecec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9319128092089151\n",
      "Recall:  0.7232465310777418\n",
      "F1 Score:  0.8144263698630136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137d9a7",
   "metadata": {},
   "source": [
    "## F1 - ORF len + FS + ORF Ratio + CpG/ORF + GC/ORF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4383ed29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8460227272727273\n"
     ]
    }
   ],
   "source": [
    "X = shuffled_dataset.drop([\"coding/noncoding\",\"Relative Codon Bias\",\"CpG Islands\",\"Transcript Length\",\"GC content\",\"Aromaticity\",\"Relative Codon Bias\",\"Isoelectric Potential\"], axis=1)   # Features\n",
    "Y = shuffled_dataset[\"coding/noncoding\"] # Target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create the Random Forest classifier and fit it to the training data\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4779f26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9365841940907998\n",
      "Recall:  0.7411138566812393\n",
      "F1 Score:  0.8274617996604414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5cf3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
